{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision\n",
    "models <https://pytorch.org/docs/stable/torchvision/models.html>`\n",
    "\n",
    "**finetuning**, \n",
    "\n",
    "start with a pretrained model and update *all* of the model’s parameters for our new\n",
    "task, in essence retraining the whole model. \n",
    "\n",
    "**feature extraction**,\n",
    "\n",
    "start with a pretrained model and only update the final layer weights\n",
    "from which we derive predictions. \n",
    "\n",
    "`<https://cs231n.github.io/transfer-learning/>`\n",
    "\n",
    "`<https://ruder.io/transfer-learning/>`\n",
    "\n",
    "both methods follow same steps:\n",
    "\n",
    "-  Initialize the pretrained model\n",
    "-  Reshape the final layer(s) to have the same number of outputs as the\n",
    "   number of classes in the new dataset\n",
    "-  Define for the optimization algorithm which parameters we want to\n",
    "   update during training\n",
    "-  Run the training step\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.2.0\n",
      "Torchvision Version:  0.4.0a0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs\n",
    "------\n",
    "\n",
    "Here are all of the parameters to change for the run. We will use the\n",
    "*hymenoptera_data* dataset which can be downloaded\n",
    "`here <https://download.pytorch.org/tutorial/hymenoptera_data.zip>`__.\n",
    "This dataset contains two classes, **bees** and **ants**, and is\n",
    "structured such that we can use the\n",
    "`ImageFolder <https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder>`__\n",
    "dataset, rather than writing our own custom dataset. Download the data\n",
    "and set the ``data_dir`` input to the root directory of the dataset. The\n",
    "``model_name`` input is the name of the model you wish to use and must\n",
    "be selected from this list:\n",
    "\n",
    "::\n",
    "\n",
    "   [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "\n",
    "The other inputs are as follows: ``num_classes`` is the number of\n",
    "classes in the dataset, ``batch_size`` is the batch size used for\n",
    "training and may be adjusted according to the capability of your\n",
    "machine, ``num_epochs`` is the number of training epochs we want to run,\n",
    "and ``feature_extract`` is a boolean that defines if we are finetuning\n",
    "or feature extracting. If ``feature_extract = False``, the model is\n",
    "finetuned and all model parameters are updated. If\n",
    "``feature_extract = True``, only the last layer parameters are updated,\n",
    "the others remain fixed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms \n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"./data/hymenoptera_data\"\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"alexnet\" #\"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 20\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 5000\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions\n",
    "----------------\n",
    "\n",
    "Before we write the code for adjusting the models, lets define a few\n",
    "helper functions.\n",
    "\n",
    "Model Training and Validation Code\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "The ``train_model`` function handles the training and validation of a\n",
    "given model. As input, it takes a PyTorch model, a dictionary of\n",
    "dataloaders, a loss function, an optimizer, a specified number of epochs\n",
    "to train and validate for, and a boolean flag for when the model is an\n",
    "Inception model. The *is_inception* flag is used to accomodate the\n",
    "*Inception v3* model, as that architecture uses an auxiliary output and\n",
    "the overall model loss respects both the auxiliary output and the final\n",
    "output, as described\n",
    "`here <https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958>`__.\n",
    "The function trains for the specified number of epochs and after each\n",
    "epoch runs a full validation step. It also keeps track of the best\n",
    "performing model (in terms of validation accuracy), and at the end of\n",
    "training returns the best performing model. After each epoch, the\n",
    "training and validation accuracies are printed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # -----------------------\n",
    "        if epoch % 50 == 0:\n",
    "            plt.plot(val_acc_history)\n",
    "            plt.show()\n",
    "            \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                print('inputs are:', inputs.shape)\n",
    "                print('labels are:', labels.shape)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Model Parameters’ .requires_grad attribute\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "This helper function sets the ``.requires_grad`` attribute of the\n",
    "parameters in the model to False when we are feature extracting. By\n",
    "default, when we load a pretrained model all of the parameters have\n",
    "``.requires_grad=True``, which is fine if we are training from scratch\n",
    "or finetuning. However, if we are feature extracting and only want to\n",
    "compute gradients for the newly initialized layer then we want all of\n",
    "the other parameters to not require gradients. This will make more sense\n",
    "later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            # print(\"let's set param grad to false\", param.shape)\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and Reshape the Networks\n",
    "-----------------------------------\n",
    "\n",
    "Now to the most interesting part. Here is where we handle the reshaping\n",
    "of each network. Note, this is not an automatic procedure and is unique\n",
    "to each model. Recall, the final layer of a CNN model, which is often\n",
    "times an FC layer, has the same number of nodes as the number of output\n",
    "classes in the dataset. Since all of the models have been pretrained on\n",
    "Imagenet, they all have output layers of size 1000, one node for each\n",
    "class. The goal here is to reshape the last layer to have the same\n",
    "number of inputs as before, AND to have the same number of outputs as\n",
    "the number of classes in the dataset. In the following sections we will\n",
    "discuss how to alter the architecture of each model individually. But\n",
    "first, there is one important detail regarding the difference between\n",
    "finetuning and feature-extraction.\n",
    "\n",
    "When feature extracting, we only want to update the parameters of the\n",
    "last layer, or in other words, we only want to update the parameters for\n",
    "the layer(s) we are reshaping. Therefore, we do not need to compute the\n",
    "gradients of the parameters that we are not changing, so for efficiency\n",
    "we set the .requires_grad attribute to False. This is important because\n",
    "by default, this attribute is set to True. Then, when we initialize the\n",
    "new layer and by default the new parameters have ``.requires_grad=True``\n",
    "so only the new layer’s parameters will be updated. When we are\n",
    "finetuning we can leave all of the .required_grad’s set to the default\n",
    "of True.\n",
    "\n",
    "Finally, notice that inception_v3 requires the input size to be\n",
    "(299,299), whereas all of the other models expect (224,224).\n",
    "\n",
    "Resnet\n",
    "~~~~~~\n",
    "\n",
    "Resnet was introduced in the paper `Deep Residual Learning for Image\n",
    "Recognition <https://arxiv.org/abs/1512.03385>`__. There are several\n",
    "variants of different sizes, including Resnet18, Resnet34, Resnet50,\n",
    "Resnet101, and Resnet152, all of which are available from torchvision\n",
    "models. Here we use Resnet18, as our dataset is small and only has two\n",
    "classes. When we print the model, we see that the last layer is a fully\n",
    "connected layer as shown below:\n",
    "\n",
    "::\n",
    "\n",
    "   (fc): Linear(in_features=512, out_features=1000, bias=True) \n",
    "\n",
    "Thus, we must reinitialize ``model.fc`` to be a Linear layer with 512\n",
    "input features and 2 output features with:\n",
    "\n",
    "::\n",
    "\n",
    "   model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "Alexnet\n",
    "~~~~~~~\n",
    "\n",
    "Alexnet was introduced in the paper `ImageNet Classification with Deep\n",
    "Convolutional Neural\n",
    "Networks <https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf>`__\n",
    "and was the first very successful CNN on the ImageNet dataset. When we\n",
    "print the model architecture, we see the model output comes from the 6th\n",
    "layer of the classifier\n",
    "\n",
    "::\n",
    "\n",
    "   (classifier): Sequential(\n",
    "       ...\n",
    "       (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "    ) \n",
    "\n",
    "To use the model with our dataset we reinitialize this layer as\n",
    "\n",
    "::\n",
    "\n",
    "   model.classifier[6] = nn.Linear(4096,num_classes)\n",
    "\n",
    "VGG\n",
    "~~~\n",
    "\n",
    "VGG was introduced in the paper `Very Deep Convolutional Networks for\n",
    "Large-Scale Image Recognition <https://arxiv.org/pdf/1409.1556.pdf>`__.\n",
    "Torchvision offers eight versions of VGG with various lengths and some\n",
    "that have batch normalizations layers. Here we use VGG-11 with batch\n",
    "normalization. The output layer is similar to Alexnet, i.e.\n",
    "\n",
    "::\n",
    "\n",
    "   (classifier): Sequential(\n",
    "       ...\n",
    "       (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
    "    )\n",
    "\n",
    "Therefore, we use the same technique to modify the output layer\n",
    "\n",
    "::\n",
    "\n",
    "   model.classifier[6] = nn.Linear(4096,num_classes)\n",
    "\n",
    "Squeezenet\n",
    "~~~~~~~~~~\n",
    "\n",
    "The Squeeznet architecture is described in the paper `SqueezeNet:\n",
    "AlexNet-level accuracy with 50x fewer parameters and <0.5MB model\n",
    "size <https://arxiv.org/abs/1602.07360>`__ and uses a different output\n",
    "structure than any of the other models shown here. Torchvision has two\n",
    "versions of Squeezenet, we use version 1.0. The output comes from a 1x1\n",
    "convolutional layer which is the 1st layer of the classifier:\n",
    "\n",
    "::\n",
    "\n",
    "   (classifier): Sequential(\n",
    "       (0): Dropout(p=0.5)\n",
    "       (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
    "       (2): ReLU(inplace)\n",
    "       (3): AvgPool2d(kernel_size=13, stride=1, padding=0)\n",
    "    ) \n",
    "\n",
    "To modify the network, we reinitialize the Conv2d layer to have an\n",
    "output feature map of depth 2 as\n",
    "\n",
    "::\n",
    "\n",
    "   model.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "Densenet\n",
    "~~~~~~~~\n",
    "\n",
    "Densenet was introduced in the paper `Densely Connected Convolutional\n",
    "Networks <https://arxiv.org/abs/1608.06993>`__. Torchvision has four\n",
    "variants of Densenet but here we only use Densenet-121. The output layer\n",
    "is a linear layer with 1024 input features:\n",
    "\n",
    "::\n",
    "\n",
    "   (classifier): Linear(in_features=1024, out_features=1000, bias=True) \n",
    "\n",
    "To reshape the network, we reinitialize the classifier’s linear layer as\n",
    "\n",
    "::\n",
    "\n",
    "   model.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "Inception v3\n",
    "~~~~~~~~~~~~\n",
    "\n",
    "Finally, Inception v3 was first described in `Rethinking the Inception\n",
    "Architecture for Computer\n",
    "Vision <https://arxiv.org/pdf/1512.00567v1.pdf>`__. This network is\n",
    "unique because it has two output layers when training. The second output\n",
    "is known as an auxiliary output and is contained in the AuxLogits part\n",
    "of the network. The primary output is a linear layer at the end of the\n",
    "network. Note, when testing we only consider the primary output. The\n",
    "auxiliary output and primary output of the loaded model are printed as:\n",
    "\n",
    "::\n",
    "\n",
    "   (AuxLogits): InceptionAux(\n",
    "       ...\n",
    "       (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
    "    )\n",
    "    ...\n",
    "   (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
    "\n",
    "To finetune this model we must reshape both layers. This is accomplished\n",
    "with the following\n",
    "\n",
    "::\n",
    "\n",
    "   model.AuxLogits.fc = nn.Linear(768, num_classes)\n",
    "   model.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "Notice, many of the models have similar output structures, but each must\n",
    "be handled slightly differently. Also, check out the printed model\n",
    "architecture of the reshaped network and make sure the number of output\n",
    "features is the same as the number of classes in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before change: AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "After change: AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "\t features.0.weight False\n",
      "\t features.0.bias False\n",
      "\t features.3.weight False\n",
      "\t features.3.bias False\n",
      "\t features.6.weight False\n",
      "\t features.6.bias False\n",
      "\t features.8.weight False\n",
      "\t features.8.bias False\n",
      "\t features.10.weight False\n",
      "\t features.10.bias False\n",
      "\t classifier.1.weight True\n",
      "\t classifier.1.bias True\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        print(\"Before change:\", model_ft)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        # model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        model_ft.classifier = nn.Sequential(*[model_ft.classifier[0], nn.Linear(num_ftrs,num_classes)])\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
    "        input_size = 224\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3 \n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "        \n",
    "    elif model_name == \"googlenet\":\n",
    "        \"\"\" googlenet\n",
    "        \"\"\"\n",
    "        model_ft = models.googlenet(pretrained=use_pretrained)\n",
    "        print('googlent:', model_ft)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "\n",
    "print('After change:', model_ft)\n",
    "for name,param in model_ft.named_parameters():\n",
    "    print(\"\\t\",name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "---------\n",
    "\n",
    "Now that we know what the input size must be, we can initialize the data\n",
    "transforms, image datasets, and the dataloaders. Notice, the models were\n",
    "pretrained with the hard-coded normalization values, as described\n",
    "`here <https://pytorch.org/docs/master/torchvision/models.html>`__.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Datasets and Dataloaders...\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device\n",
    "# torch.cuda.current_device()  # output: 0\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Optimizer\n",
    "--------------------\n",
    "\n",
    "Now that the model structure is correct, the final step for finetuning\n",
    "and feature extracting is to create an optimizer that only updates the\n",
    "desired parameters. Recall that after loading the pretrained model, but\n",
    "before reshaping, if ``feature_extract=True`` we manually set all of the\n",
    "parameter’s ``.requires_grad`` attributes to False. Then the\n",
    "reinitialized layer’s parameters have ``.requires_grad=True`` by\n",
    "default. So now we know that *all parameters that have\n",
    ".requires_grad=True should be optimized.* Next, we make a list of such\n",
    "parameters and input this list to the SGD algorithm constructor.\n",
    "\n",
    "To verify this, check out the printed parameters to learn. When\n",
    "finetuning, this list should be long and include all of the model\n",
    "parameters. However, when feature extracting this list should be short\n",
    "and only include the weights and biases of the reshaped layers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bc1143f92a67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Send the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Gather the parameters to be optimized/updated in this run. If we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#  finetuning we will be updating all parameters. However, if we are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Training and Validation Step\n",
    "--------------------------------\n",
    "\n",
    "Finally, the last step is to setup the loss for the model, then run the\n",
    "training and validation function for the set number of epochs. Notice,\n",
    "depending on the number of epochs this step may take a while on a CPU.\n",
    "Also, the default learning rate is not optimal for all of the models, so\n",
    "to achieve maximum accuracy it would be necessary to tune for each model\n",
    "separately.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e19ad607c6e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and evaluate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d0a9959a7a7e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_acc_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbest_model_wts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# If is its own copy, don't memoize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdictiter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__deepcopy__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__deepcopy__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mnew_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_offset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[0;34m(self, memo)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mnew_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cdata\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/prune/lib/python3.7/site-packages/torch/storage.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name == \"alexnet\":\n",
    "    torch.save(model_ft.state_dict()['classifier.1.weight'], 'ant_bee_Alexnet_FC_25088_2_acc8889_weight.pt')\n",
    "    torch.save(model_ft.state_dict()['classifier.1.bias'], 'ant_bee_Alexnet_FC_25088_2_acc8889_bias.pt')\n",
    "elif model_name == \"vgg\":\n",
    "    torch.save(model_ft.state_dict()['classifier.weight'], 'ant_bee_VGG19_FC_25088_2_acc94_weight.pt')\n",
    "    torch.save(model_ft.state_dict()['classifier.bias'], 'ant_bee_VGG19_FC_25088_2_acc94_bias.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9216])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.state_dict()['classifier.1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.state_dict()['classifier.1.bias'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with Model Trained from Scratch\n",
    "------------------------------------------\n",
    "\n",
    "See how the model learns if we do not use transfer\n",
    "learning. The performance of finetuning vs. feature extracting depends\n",
    "largely on the dataset but in general both transfer learning methods\n",
    "produce favorable results in terms of training time and overall accuracy\n",
    "versus a model trained from scratch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t features.0.weight False\n",
      "\t features.0.bias False\n",
      "\t features.3.weight False\n",
      "\t features.3.bias False\n",
      "\t features.6.weight False\n",
      "\t features.6.bias False\n",
      "\t features.8.weight False\n",
      "\t features.8.bias False\n",
      "\t features.10.weight False\n",
      "\t features.10.bias False\n",
      "\t classifier.1.weight True\n",
      "\t classifier.1.bias True\n",
      "\t classifier.4.weight True\n",
      "\t classifier.4.bias True\n",
      "\t classifier.6.weight True\n",
      "\t classifier.6.bias True\n",
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 0/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 15.8497 Acc: 0.0041\n",
      "val Loss: 13.1285 Acc: 0.0000\n",
      "\n",
      "Epoch 1/4999\n",
      "----------\n",
      "train Loss: 12.0782 Acc: 0.0123\n",
      "val Loss: 7.6810 Acc: 0.0588\n",
      "\n",
      "Epoch 2/4999\n",
      "----------\n",
      "train Loss: 6.7292 Acc: 0.1025\n",
      "val Loss: 3.5193 Acc: 0.4052\n",
      "\n",
      "Epoch 3/4999\n",
      "----------\n",
      "train Loss: 3.1458 Acc: 0.4344\n",
      "val Loss: 1.5856 Acc: 0.6601\n",
      "\n",
      "Epoch 4/4999\n",
      "----------\n",
      "train Loss: 1.2083 Acc: 0.7336\n",
      "val Loss: 0.9108 Acc: 0.8366\n",
      "\n",
      "Epoch 5/4999\n",
      "----------\n",
      "train Loss: 0.7216 Acc: 0.8279\n",
      "val Loss: 0.7706 Acc: 0.8693\n",
      "\n",
      "Epoch 6/4999\n",
      "----------\n",
      "train Loss: 0.5097 Acc: 0.8893\n",
      "val Loss: 0.7620 Acc: 0.8497\n",
      "\n",
      "Epoch 7/4999\n",
      "----------\n",
      "train Loss: 0.5453 Acc: 0.8770\n",
      "val Loss: 0.7669 Acc: 0.8562\n",
      "\n",
      "Epoch 8/4999\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.8566\n",
      "val Loss: 0.7406 Acc: 0.8627\n",
      "\n",
      "Epoch 9/4999\n",
      "----------\n",
      "train Loss: 0.5438 Acc: 0.8689\n",
      "val Loss: 0.6808 Acc: 0.8889\n",
      "\n",
      "Epoch 10/4999\n",
      "----------\n",
      "train Loss: 0.4413 Acc: 0.8934\n",
      "val Loss: 0.6239 Acc: 0.8758\n",
      "\n",
      "Epoch 11/4999\n",
      "----------\n",
      "train Loss: 0.3274 Acc: 0.8975\n",
      "val Loss: 0.5900 Acc: 0.8824\n",
      "\n",
      "Epoch 12/4999\n",
      "----------\n",
      "train Loss: 0.3172 Acc: 0.9221\n",
      "val Loss: 0.5729 Acc: 0.8824\n",
      "\n",
      "Epoch 13/4999\n",
      "----------\n",
      "train Loss: 0.2846 Acc: 0.9016\n",
      "val Loss: 0.5634 Acc: 0.8824\n",
      "\n",
      "Epoch 14/4999\n",
      "----------\n",
      "train Loss: 0.3045 Acc: 0.9139\n",
      "val Loss: 0.5455 Acc: 0.8758\n",
      "\n",
      "Epoch 15/4999\n",
      "----------\n",
      "train Loss: 0.2435 Acc: 0.9262\n",
      "val Loss: 0.5269 Acc: 0.8758\n",
      "\n",
      "Epoch 16/4999\n",
      "----------\n",
      "train Loss: 0.2833 Acc: 0.9139\n",
      "val Loss: 0.5170 Acc: 0.8824\n",
      "\n",
      "Epoch 17/4999\n",
      "----------\n",
      "train Loss: 0.2402 Acc: 0.9139\n",
      "val Loss: 0.5128 Acc: 0.8824\n",
      "\n",
      "Epoch 18/4999\n",
      "----------\n",
      "train Loss: 0.2691 Acc: 0.8975\n",
      "val Loss: 0.5127 Acc: 0.8758\n",
      "\n",
      "Epoch 19/4999\n",
      "----------\n",
      "train Loss: 0.1622 Acc: 0.9303\n",
      "val Loss: 0.5066 Acc: 0.8693\n",
      "\n",
      "Epoch 20/4999\n",
      "----------\n",
      "train Loss: 0.2426 Acc: 0.8975\n",
      "val Loss: 0.4910 Acc: 0.8758\n",
      "\n",
      "Epoch 21/4999\n",
      "----------\n",
      "train Loss: 0.2794 Acc: 0.8975\n",
      "val Loss: 0.4795 Acc: 0.8824\n",
      "\n",
      "Epoch 22/4999\n",
      "----------\n",
      "train Loss: 0.1295 Acc: 0.9508\n",
      "val Loss: 0.4798 Acc: 0.8758\n",
      "\n",
      "Epoch 23/4999\n",
      "----------\n",
      "train Loss: 0.2544 Acc: 0.9385\n",
      "val Loss: 0.4849 Acc: 0.8758\n",
      "\n",
      "Epoch 24/4999\n",
      "----------\n",
      "train Loss: 0.2069 Acc: 0.9262\n",
      "val Loss: 0.4839 Acc: 0.8758\n",
      "\n",
      "Epoch 25/4999\n",
      "----------\n",
      "train Loss: 0.2782 Acc: 0.9344\n",
      "val Loss: 0.4805 Acc: 0.8758\n",
      "\n",
      "Epoch 26/4999\n",
      "----------\n",
      "train Loss: 0.1425 Acc: 0.9426\n",
      "val Loss: 0.4780 Acc: 0.8758\n",
      "\n",
      "Epoch 27/4999\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9221\n",
      "val Loss: 0.4751 Acc: 0.8758\n",
      "\n",
      "Epoch 28/4999\n",
      "----------\n",
      "train Loss: 0.2325 Acc: 0.9221\n",
      "val Loss: 0.4755 Acc: 0.8824\n",
      "\n",
      "Epoch 29/4999\n",
      "----------\n",
      "train Loss: 0.1791 Acc: 0.9467\n",
      "val Loss: 0.4829 Acc: 0.8889\n",
      "\n",
      "Epoch 30/4999\n",
      "----------\n",
      "train Loss: 0.1172 Acc: 0.9467\n",
      "val Loss: 0.4888 Acc: 0.8954\n",
      "\n",
      "Epoch 31/4999\n",
      "----------\n",
      "train Loss: 0.1604 Acc: 0.9467\n",
      "val Loss: 0.4856 Acc: 0.8954\n",
      "\n",
      "Epoch 32/4999\n",
      "----------\n",
      "train Loss: 0.1199 Acc: 0.9549\n",
      "val Loss: 0.4796 Acc: 0.8954\n",
      "\n",
      "Epoch 33/4999\n",
      "----------\n",
      "train Loss: 0.1117 Acc: 0.9508\n",
      "val Loss: 0.4741 Acc: 0.8889\n",
      "\n",
      "Epoch 34/4999\n",
      "----------\n",
      "train Loss: 0.1620 Acc: 0.9467\n",
      "val Loss: 0.4678 Acc: 0.8889\n",
      "\n",
      "Epoch 35/4999\n",
      "----------\n",
      "train Loss: 0.1173 Acc: 0.9549\n",
      "val Loss: 0.4609 Acc: 0.8889\n",
      "\n",
      "Epoch 36/4999\n",
      "----------\n",
      "train Loss: 0.1116 Acc: 0.9549\n",
      "val Loss: 0.4572 Acc: 0.8889\n",
      "\n",
      "Epoch 37/4999\n",
      "----------\n",
      "train Loss: 0.1258 Acc: 0.9508\n",
      "val Loss: 0.4548 Acc: 0.8889\n",
      "\n",
      "Epoch 38/4999\n",
      "----------\n",
      "train Loss: 0.1716 Acc: 0.9303\n",
      "val Loss: 0.4519 Acc: 0.8889\n",
      "\n",
      "Epoch 39/4999\n",
      "----------\n",
      "train Loss: 0.1626 Acc: 0.9590\n",
      "val Loss: 0.4494 Acc: 0.8889\n",
      "\n",
      "Epoch 40/4999\n",
      "----------\n",
      "train Loss: 0.1319 Acc: 0.9590\n",
      "val Loss: 0.4472 Acc: 0.8889\n",
      "\n",
      "Epoch 41/4999\n",
      "----------\n",
      "train Loss: 0.0955 Acc: 0.9590\n",
      "val Loss: 0.4418 Acc: 0.8889\n",
      "\n",
      "Epoch 42/4999\n",
      "----------\n",
      "train Loss: 0.2025 Acc: 0.9344\n",
      "val Loss: 0.4371 Acc: 0.8889\n",
      "\n",
      "Epoch 43/4999\n",
      "----------\n",
      "train Loss: 0.1353 Acc: 0.9631\n",
      "val Loss: 0.4326 Acc: 0.8889\n",
      "\n",
      "Epoch 44/4999\n",
      "----------\n",
      "train Loss: 0.1145 Acc: 0.9590\n",
      "val Loss: 0.4248 Acc: 0.8824\n",
      "\n",
      "Epoch 45/4999\n",
      "----------\n",
      "train Loss: 0.1123 Acc: 0.9631\n",
      "val Loss: 0.4184 Acc: 0.8824\n",
      "\n",
      "Epoch 46/4999\n",
      "----------\n",
      "train Loss: 0.1231 Acc: 0.9590\n",
      "val Loss: 0.4117 Acc: 0.8824\n",
      "\n",
      "Epoch 47/4999\n",
      "----------\n",
      "train Loss: 0.0917 Acc: 0.9713\n",
      "val Loss: 0.4066 Acc: 0.8889\n",
      "\n",
      "Epoch 48/4999\n",
      "----------\n",
      "train Loss: 0.1339 Acc: 0.9467\n",
      "val Loss: 0.4014 Acc: 0.8889\n",
      "\n",
      "Epoch 49/4999\n",
      "----------\n",
      "train Loss: 0.1206 Acc: 0.9549\n",
      "val Loss: 0.3967 Acc: 0.8889\n",
      "\n",
      "Epoch 50/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1063 Acc: 0.9590\n",
      "val Loss: 0.3945 Acc: 0.8889\n",
      "\n",
      "Epoch 51/4999\n",
      "----------\n",
      "train Loss: 0.1017 Acc: 0.9631\n",
      "val Loss: 0.3955 Acc: 0.8889\n",
      "\n",
      "Epoch 52/4999\n",
      "----------\n",
      "train Loss: 0.1462 Acc: 0.9508\n",
      "val Loss: 0.3986 Acc: 0.8889\n",
      "\n",
      "Epoch 53/4999\n",
      "----------\n",
      "train Loss: 0.1078 Acc: 0.9631\n",
      "val Loss: 0.4019 Acc: 0.8889\n",
      "\n",
      "Epoch 54/4999\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9713\n",
      "val Loss: 0.4053 Acc: 0.8889\n",
      "\n",
      "Epoch 55/4999\n",
      "----------\n",
      "train Loss: 0.0975 Acc: 0.9549\n",
      "val Loss: 0.4046 Acc: 0.8889\n",
      "\n",
      "Epoch 56/4999\n",
      "----------\n",
      "train Loss: 0.1100 Acc: 0.9549\n",
      "val Loss: 0.4008 Acc: 0.8889\n",
      "\n",
      "Epoch 57/4999\n",
      "----------\n",
      "train Loss: 0.0747 Acc: 0.9795\n",
      "val Loss: 0.3973 Acc: 0.8889\n",
      "\n",
      "Epoch 58/4999\n",
      "----------\n",
      "train Loss: 0.1389 Acc: 0.9385\n",
      "val Loss: 0.3959 Acc: 0.8889\n",
      "\n",
      "Epoch 59/4999\n",
      "----------\n",
      "train Loss: 0.1188 Acc: 0.9467\n",
      "val Loss: 0.3948 Acc: 0.8889\n",
      "\n",
      "Epoch 60/4999\n",
      "----------\n",
      "train Loss: 0.0750 Acc: 0.9672\n",
      "val Loss: 0.3911 Acc: 0.8889\n",
      "\n",
      "Epoch 61/4999\n",
      "----------\n",
      "train Loss: 0.1268 Acc: 0.9508\n",
      "val Loss: 0.3885 Acc: 0.8889\n",
      "\n",
      "Epoch 62/4999\n",
      "----------\n",
      "train Loss: 0.1084 Acc: 0.9672\n",
      "val Loss: 0.3884 Acc: 0.8889\n",
      "\n",
      "Epoch 63/4999\n",
      "----------\n",
      "train Loss: 0.0907 Acc: 0.9590\n",
      "val Loss: 0.3878 Acc: 0.8889\n",
      "\n",
      "Epoch 64/4999\n",
      "----------\n",
      "train Loss: 0.0956 Acc: 0.9549\n",
      "val Loss: 0.3869 Acc: 0.8889\n",
      "\n",
      "Epoch 65/4999\n",
      "----------\n",
      "train Loss: 0.1559 Acc: 0.9508\n",
      "val Loss: 0.3856 Acc: 0.8889\n",
      "\n",
      "Epoch 66/4999\n",
      "----------\n",
      "train Loss: 0.0755 Acc: 0.9672\n",
      "val Loss: 0.3855 Acc: 0.8889\n",
      "\n",
      "Epoch 67/4999\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9713\n",
      "val Loss: 0.3854 Acc: 0.8889\n",
      "\n",
      "Epoch 68/4999\n",
      "----------\n",
      "train Loss: 0.1412 Acc: 0.9672\n",
      "val Loss: 0.3849 Acc: 0.8824\n",
      "\n",
      "Epoch 69/4999\n",
      "----------\n",
      "train Loss: 0.0996 Acc: 0.9631\n",
      "val Loss: 0.3843 Acc: 0.8889\n",
      "\n",
      "Epoch 70/4999\n",
      "----------\n",
      "train Loss: 0.0954 Acc: 0.9672\n",
      "val Loss: 0.3869 Acc: 0.8889\n",
      "\n",
      "Epoch 71/4999\n",
      "----------\n",
      "train Loss: 0.0867 Acc: 0.9754\n",
      "val Loss: 0.3912 Acc: 0.8889\n",
      "\n",
      "Epoch 72/4999\n",
      "----------\n",
      "train Loss: 0.1115 Acc: 0.9590\n",
      "val Loss: 0.3962 Acc: 0.8889\n",
      "\n",
      "Epoch 73/4999\n",
      "----------\n",
      "train Loss: 0.0869 Acc: 0.9672\n",
      "val Loss: 0.3984 Acc: 0.8889\n",
      "\n",
      "Epoch 74/4999\n",
      "----------\n",
      "train Loss: 0.0747 Acc: 0.9713\n",
      "val Loss: 0.3968 Acc: 0.8889\n",
      "\n",
      "Epoch 75/4999\n",
      "----------\n",
      "train Loss: 0.0777 Acc: 0.9754\n",
      "val Loss: 0.3919 Acc: 0.8889\n",
      "\n",
      "Epoch 76/4999\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9713\n",
      "val Loss: 0.3870 Acc: 0.8889\n",
      "\n",
      "Epoch 77/4999\n",
      "----------\n",
      "train Loss: 0.0726 Acc: 0.9795\n",
      "val Loss: 0.3834 Acc: 0.8889\n",
      "\n",
      "Epoch 78/4999\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9631\n",
      "val Loss: 0.3815 Acc: 0.8889\n",
      "\n",
      "Epoch 79/4999\n",
      "----------\n",
      "train Loss: 0.0903 Acc: 0.9713\n",
      "val Loss: 0.3792 Acc: 0.8889\n",
      "\n",
      "Epoch 80/4999\n",
      "----------\n",
      "train Loss: 0.0513 Acc: 0.9836\n",
      "val Loss: 0.3779 Acc: 0.8954\n",
      "\n",
      "Epoch 81/4999\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9713\n",
      "val Loss: 0.3768 Acc: 0.8889\n",
      "\n",
      "Epoch 82/4999\n",
      "----------\n",
      "train Loss: 0.0731 Acc: 0.9836\n",
      "val Loss: 0.3761 Acc: 0.8889\n",
      "\n",
      "Epoch 83/4999\n",
      "----------\n",
      "train Loss: 0.0789 Acc: 0.9672\n",
      "val Loss: 0.3761 Acc: 0.8889\n",
      "\n",
      "Epoch 84/4999\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9836\n",
      "val Loss: 0.3762 Acc: 0.8889\n",
      "\n",
      "Epoch 85/4999\n",
      "----------\n",
      "train Loss: 0.0927 Acc: 0.9754\n",
      "val Loss: 0.3770 Acc: 0.8889\n",
      "\n",
      "Epoch 86/4999\n",
      "----------\n",
      "train Loss: 0.0992 Acc: 0.9590\n",
      "val Loss: 0.3778 Acc: 0.8889\n",
      "\n",
      "Epoch 87/4999\n",
      "----------\n",
      "train Loss: 0.0904 Acc: 0.9672\n",
      "val Loss: 0.3776 Acc: 0.8889\n",
      "\n",
      "Epoch 88/4999\n",
      "----------\n",
      "train Loss: 0.0656 Acc: 0.9795\n",
      "val Loss: 0.3773 Acc: 0.8889\n",
      "\n",
      "Epoch 89/4999\n",
      "----------\n",
      "train Loss: 0.0903 Acc: 0.9631\n",
      "val Loss: 0.3760 Acc: 0.8889\n",
      "\n",
      "Epoch 90/4999\n",
      "----------\n",
      "train Loss: 0.0816 Acc: 0.9672\n",
      "val Loss: 0.3747 Acc: 0.8889\n",
      "\n",
      "Epoch 91/4999\n",
      "----------\n",
      "train Loss: 0.1125 Acc: 0.9713\n",
      "val Loss: 0.3735 Acc: 0.8889\n",
      "\n",
      "Epoch 92/4999\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9672\n",
      "val Loss: 0.3725 Acc: 0.8889\n",
      "\n",
      "Epoch 93/4999\n",
      "----------\n",
      "train Loss: 0.0894 Acc: 0.9631\n",
      "val Loss: 0.3722 Acc: 0.8954\n",
      "\n",
      "Epoch 94/4999\n",
      "----------\n",
      "train Loss: 0.1197 Acc: 0.9590\n",
      "val Loss: 0.3716 Acc: 0.8954\n",
      "\n",
      "Epoch 95/4999\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9877\n",
      "val Loss: 0.3717 Acc: 0.8954\n",
      "\n",
      "Epoch 96/4999\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.9672\n",
      "val Loss: 0.3739 Acc: 0.8954\n",
      "\n",
      "Epoch 97/4999\n",
      "----------\n",
      "train Loss: 0.0547 Acc: 0.9795\n",
      "val Loss: 0.3753 Acc: 0.8954\n",
      "\n",
      "Epoch 98/4999\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.9754\n",
      "val Loss: 0.3741 Acc: 0.8954\n",
      "\n",
      "Epoch 99/4999\n",
      "----------\n",
      "train Loss: 0.0967 Acc: 0.9590\n",
      "val Loss: 0.3721 Acc: 0.8954\n",
      "\n",
      "Epoch 100/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.1167 Acc: 0.9467\n",
      "val Loss: 0.3720 Acc: 0.8954\n",
      "\n",
      "Epoch 101/4999\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9836\n",
      "val Loss: 0.3721 Acc: 0.8954\n",
      "\n",
      "Epoch 102/4999\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9795\n",
      "val Loss: 0.3716 Acc: 0.8954\n",
      "\n",
      "Epoch 103/4999\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9713\n",
      "val Loss: 0.3728 Acc: 0.8954\n",
      "\n",
      "Epoch 104/4999\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9877\n",
      "val Loss: 0.3730 Acc: 0.8954\n",
      "\n",
      "Epoch 105/4999\n",
      "----------\n",
      "train Loss: 0.0557 Acc: 0.9836\n",
      "val Loss: 0.3710 Acc: 0.8954\n",
      "\n",
      "Epoch 106/4999\n",
      "----------\n",
      "train Loss: 0.0981 Acc: 0.9631\n",
      "val Loss: 0.3696 Acc: 0.8954\n",
      "\n",
      "Epoch 107/4999\n",
      "----------\n",
      "train Loss: 0.0937 Acc: 0.9713\n",
      "val Loss: 0.3680 Acc: 0.8954\n",
      "\n",
      "Epoch 108/4999\n",
      "----------\n",
      "train Loss: 0.0791 Acc: 0.9631\n",
      "val Loss: 0.3665 Acc: 0.8954\n",
      "\n",
      "Epoch 109/4999\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9877\n",
      "val Loss: 0.3661 Acc: 0.8954\n",
      "\n",
      "Epoch 110/4999\n",
      "----------\n",
      "train Loss: 0.0971 Acc: 0.9713\n",
      "val Loss: 0.3673 Acc: 0.8954\n",
      "\n",
      "Epoch 111/4999\n",
      "----------\n",
      "train Loss: 0.1102 Acc: 0.9549\n",
      "val Loss: 0.3691 Acc: 0.8954\n",
      "\n",
      "Epoch 112/4999\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9754\n",
      "val Loss: 0.3696 Acc: 0.8954\n",
      "\n",
      "Epoch 113/4999\n",
      "----------\n",
      "train Loss: 0.0619 Acc: 0.9795\n",
      "val Loss: 0.3707 Acc: 0.8954\n",
      "\n",
      "Epoch 114/4999\n",
      "----------\n",
      "train Loss: 0.0698 Acc: 0.9754\n",
      "val Loss: 0.3721 Acc: 0.8954\n",
      "\n",
      "Epoch 115/4999\n",
      "----------\n",
      "train Loss: 0.0532 Acc: 0.9836\n",
      "val Loss: 0.3737 Acc: 0.8889\n",
      "\n",
      "Epoch 116/4999\n",
      "----------\n",
      "train Loss: 0.1498 Acc: 0.9590\n",
      "val Loss: 0.3754 Acc: 0.8889\n",
      "\n",
      "Epoch 117/4999\n",
      "----------\n",
      "train Loss: 0.0568 Acc: 0.9672\n",
      "val Loss: 0.3774 Acc: 0.8889\n",
      "\n",
      "Epoch 118/4999\n",
      "----------\n",
      "train Loss: 0.0829 Acc: 0.9713\n",
      "val Loss: 0.3781 Acc: 0.8889\n",
      "\n",
      "Epoch 119/4999\n",
      "----------\n",
      "train Loss: 0.0896 Acc: 0.9590\n",
      "val Loss: 0.3788 Acc: 0.8889\n",
      "\n",
      "Epoch 120/4999\n",
      "----------\n",
      "train Loss: 0.0784 Acc: 0.9754\n",
      "val Loss: 0.3803 Acc: 0.8889\n",
      "\n",
      "Epoch 121/4999\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9836\n",
      "val Loss: 0.3823 Acc: 0.8889\n",
      "\n",
      "Epoch 122/4999\n",
      "----------\n",
      "train Loss: 0.0699 Acc: 0.9754\n",
      "val Loss: 0.3834 Acc: 0.8889\n",
      "\n",
      "Epoch 123/4999\n",
      "----------\n",
      "train Loss: 0.0775 Acc: 0.9754\n",
      "val Loss: 0.3819 Acc: 0.8889\n",
      "\n",
      "Epoch 124/4999\n",
      "----------\n",
      "train Loss: 0.0746 Acc: 0.9754\n",
      "val Loss: 0.3798 Acc: 0.8889\n",
      "\n",
      "Epoch 125/4999\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9713\n",
      "val Loss: 0.3791 Acc: 0.8889\n",
      "\n",
      "Epoch 126/4999\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9877\n",
      "val Loss: 0.3797 Acc: 0.8889\n",
      "\n",
      "Epoch 127/4999\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9877\n",
      "val Loss: 0.3810 Acc: 0.8889\n",
      "\n",
      "Epoch 128/4999\n",
      "----------\n",
      "train Loss: 0.0750 Acc: 0.9631\n",
      "val Loss: 0.3822 Acc: 0.8889\n",
      "\n",
      "Epoch 129/4999\n",
      "----------\n",
      "train Loss: 0.0729 Acc: 0.9713\n",
      "val Loss: 0.3843 Acc: 0.8889\n",
      "\n",
      "Epoch 130/4999\n",
      "----------\n",
      "train Loss: 0.0932 Acc: 0.9713\n",
      "val Loss: 0.3853 Acc: 0.8889\n",
      "\n",
      "Epoch 131/4999\n",
      "----------\n",
      "train Loss: 0.0689 Acc: 0.9836\n",
      "val Loss: 0.3852 Acc: 0.8889\n",
      "\n",
      "Epoch 132/4999\n",
      "----------\n",
      "train Loss: 0.0766 Acc: 0.9795\n",
      "val Loss: 0.3842 Acc: 0.8889\n",
      "\n",
      "Epoch 133/4999\n",
      "----------\n",
      "train Loss: 0.0580 Acc: 0.9754\n",
      "val Loss: 0.3803 Acc: 0.8889\n",
      "\n",
      "Epoch 134/4999\n",
      "----------\n",
      "train Loss: 0.0429 Acc: 0.9918\n",
      "val Loss: 0.3762 Acc: 0.8889\n",
      "\n",
      "Epoch 135/4999\n",
      "----------\n",
      "train Loss: 0.0636 Acc: 0.9795\n",
      "val Loss: 0.3748 Acc: 0.8889\n",
      "\n",
      "Epoch 136/4999\n",
      "----------\n",
      "train Loss: 0.0456 Acc: 0.9836\n",
      "val Loss: 0.3739 Acc: 0.8889\n",
      "\n",
      "Epoch 137/4999\n",
      "----------\n",
      "train Loss: 0.0542 Acc: 0.9754\n",
      "val Loss: 0.3732 Acc: 0.8889\n",
      "\n",
      "Epoch 138/4999\n",
      "----------\n",
      "train Loss: 0.0534 Acc: 0.9877\n",
      "val Loss: 0.3719 Acc: 0.8954\n",
      "\n",
      "Epoch 139/4999\n",
      "----------\n",
      "train Loss: 0.0466 Acc: 0.9877\n",
      "val Loss: 0.3700 Acc: 0.8954\n",
      "\n",
      "Epoch 140/4999\n",
      "----------\n",
      "train Loss: 0.0616 Acc: 0.9795\n",
      "val Loss: 0.3681 Acc: 0.8889\n",
      "\n",
      "Epoch 141/4999\n",
      "----------\n",
      "train Loss: 0.0737 Acc: 0.9754\n",
      "val Loss: 0.3670 Acc: 0.8889\n",
      "\n",
      "Epoch 142/4999\n",
      "----------\n",
      "train Loss: 0.0529 Acc: 0.9754\n",
      "val Loss: 0.3668 Acc: 0.8889\n",
      "\n",
      "Epoch 143/4999\n",
      "----------\n",
      "train Loss: 0.0695 Acc: 0.9795\n",
      "val Loss: 0.3679 Acc: 0.8889\n",
      "\n",
      "Epoch 144/4999\n",
      "----------\n",
      "train Loss: 0.0770 Acc: 0.9672\n",
      "val Loss: 0.3690 Acc: 0.8889\n",
      "\n",
      "Epoch 145/4999\n",
      "----------\n",
      "train Loss: 0.0703 Acc: 0.9754\n",
      "val Loss: 0.3705 Acc: 0.8889\n",
      "\n",
      "Epoch 146/4999\n",
      "----------\n",
      "train Loss: 0.0531 Acc: 0.9754\n",
      "val Loss: 0.3732 Acc: 0.8889\n",
      "\n",
      "Epoch 147/4999\n",
      "----------\n",
      "train Loss: 0.0862 Acc: 0.9713\n",
      "val Loss: 0.3756 Acc: 0.8889\n",
      "\n",
      "Epoch 148/4999\n",
      "----------\n",
      "train Loss: 0.0590 Acc: 0.9754\n",
      "val Loss: 0.3754 Acc: 0.8889\n",
      "\n",
      "Epoch 149/4999\n",
      "----------\n",
      "train Loss: 0.0974 Acc: 0.9795\n",
      "val Loss: 0.3722 Acc: 0.8889\n",
      "\n",
      "Epoch 150/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0509 Acc: 0.9877\n",
      "val Loss: 0.3682 Acc: 0.8889\n",
      "\n",
      "Epoch 151/4999\n",
      "----------\n",
      "train Loss: 0.0660 Acc: 0.9754\n",
      "val Loss: 0.3660 Acc: 0.8889\n",
      "\n",
      "Epoch 152/4999\n",
      "----------\n",
      "train Loss: 0.0432 Acc: 0.9836\n",
      "val Loss: 0.3648 Acc: 0.8889\n",
      "\n",
      "Epoch 153/4999\n",
      "----------\n",
      "train Loss: 0.0581 Acc: 0.9795\n",
      "val Loss: 0.3643 Acc: 0.8889\n",
      "\n",
      "Epoch 154/4999\n",
      "----------\n",
      "train Loss: 0.0802 Acc: 0.9713\n",
      "val Loss: 0.3643 Acc: 0.8889\n",
      "\n",
      "Epoch 155/4999\n",
      "----------\n",
      "train Loss: 0.0833 Acc: 0.9713\n",
      "val Loss: 0.3650 Acc: 0.8889\n",
      "\n",
      "Epoch 156/4999\n",
      "----------\n",
      "train Loss: 0.1127 Acc: 0.9467\n",
      "val Loss: 0.3660 Acc: 0.8889\n",
      "\n",
      "Epoch 157/4999\n",
      "----------\n",
      "train Loss: 0.0829 Acc: 0.9713\n",
      "val Loss: 0.3667 Acc: 0.8889\n",
      "\n",
      "Epoch 158/4999\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.9836\n",
      "val Loss: 0.3669 Acc: 0.8889\n",
      "\n",
      "Epoch 159/4999\n",
      "----------\n",
      "train Loss: 0.0647 Acc: 0.9795\n",
      "val Loss: 0.3677 Acc: 0.8889\n",
      "\n",
      "Epoch 160/4999\n",
      "----------\n",
      "train Loss: 0.0480 Acc: 0.9877\n",
      "val Loss: 0.3694 Acc: 0.8889\n",
      "\n",
      "Epoch 161/4999\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9754\n",
      "val Loss: 0.3705 Acc: 0.8889\n",
      "\n",
      "Epoch 162/4999\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.9836\n",
      "val Loss: 0.3707 Acc: 0.8889\n",
      "\n",
      "Epoch 163/4999\n",
      "----------\n",
      "train Loss: 0.0687 Acc: 0.9754\n",
      "val Loss: 0.3704 Acc: 0.8889\n",
      "\n",
      "Epoch 164/4999\n",
      "----------\n",
      "train Loss: 0.0525 Acc: 0.9795\n",
      "val Loss: 0.3699 Acc: 0.8889\n",
      "\n",
      "Epoch 165/4999\n",
      "----------\n",
      "train Loss: 0.0774 Acc: 0.9631\n",
      "val Loss: 0.3700 Acc: 0.8889\n",
      "\n",
      "Epoch 166/4999\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9754\n",
      "val Loss: 0.3709 Acc: 0.8889\n",
      "\n",
      "Epoch 167/4999\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.9672\n",
      "val Loss: 0.3729 Acc: 0.8889\n",
      "\n",
      "Epoch 168/4999\n",
      "----------\n",
      "train Loss: 0.0570 Acc: 0.9713\n",
      "val Loss: 0.3758 Acc: 0.8889\n",
      "\n",
      "Epoch 169/4999\n",
      "----------\n",
      "train Loss: 0.0607 Acc: 0.9713\n",
      "val Loss: 0.3803 Acc: 0.8889\n",
      "\n",
      "Epoch 170/4999\n",
      "----------\n",
      "train Loss: 0.0268 Acc: 0.9959\n",
      "val Loss: 0.3848 Acc: 0.8889\n",
      "\n",
      "Epoch 171/4999\n",
      "----------\n",
      "train Loss: 0.0577 Acc: 0.9672\n",
      "val Loss: 0.3859 Acc: 0.8824\n",
      "\n",
      "Epoch 172/4999\n",
      "----------\n",
      "train Loss: 0.0881 Acc: 0.9672\n",
      "val Loss: 0.3853 Acc: 0.8824\n",
      "\n",
      "Epoch 173/4999\n",
      "----------\n",
      "train Loss: 0.0707 Acc: 0.9754\n",
      "val Loss: 0.3804 Acc: 0.8889\n",
      "\n",
      "Epoch 174/4999\n",
      "----------\n",
      "train Loss: 0.0598 Acc: 0.9754\n",
      "val Loss: 0.3712 Acc: 0.8889\n",
      "\n",
      "Epoch 175/4999\n",
      "----------\n",
      "train Loss: 0.0695 Acc: 0.9672\n",
      "val Loss: 0.3654 Acc: 0.8889\n",
      "\n",
      "Epoch 176/4999\n",
      "----------\n",
      "train Loss: 0.0658 Acc: 0.9672\n",
      "val Loss: 0.3624 Acc: 0.8889\n",
      "\n",
      "Epoch 177/4999\n",
      "----------\n",
      "train Loss: 0.0836 Acc: 0.9631\n",
      "val Loss: 0.3613 Acc: 0.8889\n",
      "\n",
      "Epoch 178/4999\n",
      "----------\n",
      "train Loss: 0.0641 Acc: 0.9754\n",
      "val Loss: 0.3612 Acc: 0.9020\n",
      "\n",
      "Epoch 179/4999\n",
      "----------\n",
      "train Loss: 0.0668 Acc: 0.9713\n",
      "val Loss: 0.3615 Acc: 0.9020\n",
      "\n",
      "Epoch 180/4999\n",
      "----------\n",
      "train Loss: 0.0424 Acc: 0.9877\n",
      "val Loss: 0.3614 Acc: 0.9020\n",
      "\n",
      "Epoch 181/4999\n",
      "----------\n",
      "train Loss: 0.0552 Acc: 0.9918\n",
      "val Loss: 0.3609 Acc: 0.9020\n",
      "\n",
      "Epoch 182/4999\n",
      "----------\n",
      "train Loss: 0.0633 Acc: 0.9795\n",
      "val Loss: 0.3603 Acc: 0.9020\n",
      "\n",
      "Epoch 183/4999\n",
      "----------\n",
      "train Loss: 0.0592 Acc: 0.9795\n",
      "val Loss: 0.3607 Acc: 0.8889\n",
      "\n",
      "Epoch 184/4999\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.9672\n",
      "val Loss: 0.3633 Acc: 0.8889\n",
      "\n",
      "Epoch 185/4999\n",
      "----------\n",
      "train Loss: 0.0606 Acc: 0.9713\n",
      "val Loss: 0.3659 Acc: 0.8889\n",
      "\n",
      "Epoch 186/4999\n",
      "----------\n",
      "train Loss: 0.0516 Acc: 0.9795\n",
      "val Loss: 0.3683 Acc: 0.8889\n",
      "\n",
      "Epoch 187/4999\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.9877\n",
      "val Loss: 0.3703 Acc: 0.8889\n",
      "\n",
      "Epoch 188/4999\n",
      "----------\n",
      "train Loss: 0.0558 Acc: 0.9795\n",
      "val Loss: 0.3718 Acc: 0.8889\n",
      "\n",
      "Epoch 189/4999\n",
      "----------\n",
      "train Loss: 0.1043 Acc: 0.9590\n",
      "val Loss: 0.3724 Acc: 0.8889\n",
      "\n",
      "Epoch 190/4999\n",
      "----------\n",
      "train Loss: 0.0526 Acc: 0.9754\n",
      "val Loss: 0.3728 Acc: 0.8889\n",
      "\n",
      "Epoch 191/4999\n",
      "----------\n",
      "train Loss: 0.0701 Acc: 0.9672\n",
      "val Loss: 0.3734 Acc: 0.8954\n",
      "\n",
      "Epoch 192/4999\n",
      "----------\n",
      "train Loss: 0.0682 Acc: 0.9754\n",
      "val Loss: 0.3737 Acc: 0.8954\n",
      "\n",
      "Epoch 193/4999\n",
      "----------\n",
      "train Loss: 0.0566 Acc: 0.9754\n",
      "val Loss: 0.3740 Acc: 0.8954\n",
      "\n",
      "Epoch 194/4999\n",
      "----------\n",
      "train Loss: 0.0513 Acc: 0.9836\n",
      "val Loss: 0.3742 Acc: 0.8954\n",
      "\n",
      "Epoch 195/4999\n",
      "----------\n",
      "train Loss: 0.0554 Acc: 0.9836\n",
      "val Loss: 0.3746 Acc: 0.8954\n",
      "\n",
      "Epoch 196/4999\n",
      "----------\n",
      "train Loss: 0.0292 Acc: 0.9918\n",
      "val Loss: 0.3753 Acc: 0.8954\n",
      "\n",
      "Epoch 197/4999\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 0.9918\n",
      "val Loss: 0.3757 Acc: 0.8954\n",
      "\n",
      "Epoch 198/4999\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 0.9795\n",
      "val Loss: 0.3770 Acc: 0.8954\n",
      "\n",
      "Epoch 199/4999\n",
      "----------\n",
      "train Loss: 0.0488 Acc: 0.9836\n",
      "val Loss: 0.3784 Acc: 0.8954\n",
      "\n",
      "Epoch 200/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0495 Acc: 0.9836\n",
      "val Loss: 0.3795 Acc: 0.8889\n",
      "\n",
      "Epoch 201/4999\n",
      "----------\n",
      "train Loss: 0.0904 Acc: 0.9631\n",
      "val Loss: 0.3775 Acc: 0.8954\n",
      "\n",
      "Epoch 202/4999\n",
      "----------\n",
      "train Loss: 0.0769 Acc: 0.9713\n",
      "val Loss: 0.3759 Acc: 0.8954\n",
      "\n",
      "Epoch 203/4999\n",
      "----------\n",
      "train Loss: 0.0748 Acc: 0.9795\n",
      "val Loss: 0.3743 Acc: 0.8954\n",
      "\n",
      "Epoch 204/4999\n",
      "----------\n",
      "train Loss: 0.0417 Acc: 0.9877\n",
      "val Loss: 0.3713 Acc: 0.8954\n",
      "\n",
      "Epoch 205/4999\n",
      "----------\n",
      "train Loss: 0.0386 Acc: 0.9795\n",
      "val Loss: 0.3688 Acc: 0.8954\n",
      "\n",
      "Epoch 206/4999\n",
      "----------\n",
      "train Loss: 0.0713 Acc: 0.9795\n",
      "val Loss: 0.3676 Acc: 0.8954\n",
      "\n",
      "Epoch 207/4999\n",
      "----------\n",
      "train Loss: 0.0885 Acc: 0.9795\n",
      "val Loss: 0.3676 Acc: 0.8954\n",
      "\n",
      "Epoch 208/4999\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.9877\n",
      "val Loss: 0.3679 Acc: 0.8954\n",
      "\n",
      "Epoch 209/4999\n",
      "----------\n",
      "train Loss: 0.1012 Acc: 0.9672\n",
      "val Loss: 0.3661 Acc: 0.8954\n",
      "\n",
      "Epoch 210/4999\n",
      "----------\n",
      "train Loss: 0.0564 Acc: 0.9754\n",
      "val Loss: 0.3639 Acc: 0.8954\n",
      "\n",
      "Epoch 211/4999\n",
      "----------\n",
      "train Loss: 0.0595 Acc: 0.9795\n",
      "val Loss: 0.3622 Acc: 0.8954\n",
      "\n",
      "Epoch 212/4999\n",
      "----------\n",
      "train Loss: 0.0451 Acc: 0.9836\n",
      "val Loss: 0.3608 Acc: 0.8954\n",
      "\n",
      "Epoch 213/4999\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.9754\n",
      "val Loss: 0.3597 Acc: 0.8954\n",
      "\n",
      "Epoch 214/4999\n",
      "----------\n",
      "train Loss: 0.0673 Acc: 0.9713\n",
      "val Loss: 0.3588 Acc: 0.9020\n",
      "\n",
      "Epoch 215/4999\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9754\n",
      "val Loss: 0.3589 Acc: 0.9020\n",
      "\n",
      "Epoch 216/4999\n",
      "----------\n",
      "train Loss: 0.0496 Acc: 0.9795\n",
      "val Loss: 0.3600 Acc: 0.9020\n",
      "\n",
      "Epoch 217/4999\n",
      "----------\n",
      "train Loss: 0.0471 Acc: 0.9836\n",
      "val Loss: 0.3621 Acc: 0.8954\n",
      "\n",
      "Epoch 218/4999\n",
      "----------\n",
      "train Loss: 0.0433 Acc: 0.9918\n",
      "val Loss: 0.3637 Acc: 0.8954\n",
      "\n",
      "Epoch 219/4999\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9836\n",
      "val Loss: 0.3656 Acc: 0.8954\n",
      "\n",
      "Epoch 220/4999\n",
      "----------\n",
      "train Loss: 0.0342 Acc: 0.9918\n",
      "val Loss: 0.3679 Acc: 0.8954\n",
      "\n",
      "Epoch 221/4999\n",
      "----------\n",
      "train Loss: 0.0725 Acc: 0.9836\n",
      "val Loss: 0.3687 Acc: 0.8954\n",
      "\n",
      "Epoch 222/4999\n",
      "----------\n",
      "train Loss: 0.0376 Acc: 0.9836\n",
      "val Loss: 0.3688 Acc: 0.8954\n",
      "\n",
      "Epoch 223/4999\n",
      "----------\n",
      "train Loss: 0.0690 Acc: 0.9754\n",
      "val Loss: 0.3701 Acc: 0.8954\n",
      "\n",
      "Epoch 224/4999\n",
      "----------\n",
      "train Loss: 0.0495 Acc: 0.9795\n",
      "val Loss: 0.3719 Acc: 0.8954\n",
      "\n",
      "Epoch 225/4999\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 0.9836\n",
      "val Loss: 0.3741 Acc: 0.8954\n",
      "\n",
      "Epoch 226/4999\n",
      "----------\n",
      "train Loss: 0.0308 Acc: 0.9877\n",
      "val Loss: 0.3773 Acc: 0.8954\n",
      "\n",
      "Epoch 227/4999\n",
      "----------\n",
      "train Loss: 0.0543 Acc: 0.9795\n",
      "val Loss: 0.3820 Acc: 0.8889\n",
      "\n",
      "Epoch 228/4999\n",
      "----------\n",
      "train Loss: 0.0525 Acc: 0.9836\n",
      "val Loss: 0.3860 Acc: 0.8954\n",
      "\n",
      "Epoch 229/4999\n",
      "----------\n",
      "train Loss: 0.0826 Acc: 0.9631\n",
      "val Loss: 0.3857 Acc: 0.8954\n",
      "\n",
      "Epoch 230/4999\n",
      "----------\n",
      "train Loss: 0.0531 Acc: 0.9795\n",
      "val Loss: 0.3840 Acc: 0.8954\n",
      "\n",
      "Epoch 231/4999\n",
      "----------\n",
      "train Loss: 0.0724 Acc: 0.9713\n",
      "val Loss: 0.3812 Acc: 0.8889\n",
      "\n",
      "Epoch 232/4999\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.9877\n",
      "val Loss: 0.3790 Acc: 0.8889\n",
      "\n",
      "Epoch 233/4999\n",
      "----------\n",
      "train Loss: 0.0171 Acc: 0.9959\n",
      "val Loss: 0.3771 Acc: 0.8889\n",
      "\n",
      "Epoch 234/4999\n",
      "----------\n",
      "train Loss: 0.0317 Acc: 0.9918\n",
      "val Loss: 0.3751 Acc: 0.8889\n",
      "\n",
      "Epoch 235/4999\n",
      "----------\n",
      "train Loss: 0.0710 Acc: 0.9795\n",
      "val Loss: 0.3725 Acc: 0.8954\n",
      "\n",
      "Epoch 236/4999\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.9754\n",
      "val Loss: 0.3700 Acc: 0.8954\n",
      "\n",
      "Epoch 237/4999\n",
      "----------\n",
      "train Loss: 0.0631 Acc: 0.9672\n",
      "val Loss: 0.3677 Acc: 0.8954\n",
      "\n",
      "Epoch 238/4999\n",
      "----------\n",
      "train Loss: 0.0502 Acc: 0.9836\n",
      "val Loss: 0.3660 Acc: 0.8954\n",
      "\n",
      "Epoch 239/4999\n",
      "----------\n",
      "train Loss: 0.0304 Acc: 0.9959\n",
      "val Loss: 0.3649 Acc: 0.8954\n",
      "\n",
      "Epoch 240/4999\n",
      "----------\n",
      "train Loss: 0.0548 Acc: 0.9795\n",
      "val Loss: 0.3644 Acc: 0.8954\n",
      "\n",
      "Epoch 241/4999\n",
      "----------\n",
      "train Loss: 0.0607 Acc: 0.9795\n",
      "val Loss: 0.3639 Acc: 0.8954\n",
      "\n",
      "Epoch 242/4999\n",
      "----------\n",
      "train Loss: 0.0441 Acc: 0.9795\n",
      "val Loss: 0.3637 Acc: 0.8954\n",
      "\n",
      "Epoch 243/4999\n",
      "----------\n",
      "train Loss: 0.0803 Acc: 0.9631\n",
      "val Loss: 0.3639 Acc: 0.8889\n",
      "\n",
      "Epoch 244/4999\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 0.9836\n",
      "val Loss: 0.3647 Acc: 0.8889\n",
      "\n",
      "Epoch 245/4999\n",
      "----------\n",
      "train Loss: 0.0602 Acc: 0.9836\n",
      "val Loss: 0.3664 Acc: 0.8889\n",
      "\n",
      "Epoch 246/4999\n",
      "----------\n",
      "train Loss: 0.0369 Acc: 0.9836\n",
      "val Loss: 0.3681 Acc: 0.8889\n",
      "\n",
      "Epoch 247/4999\n",
      "----------\n",
      "train Loss: 0.0637 Acc: 0.9877\n",
      "val Loss: 0.3688 Acc: 0.8889\n",
      "\n",
      "Epoch 248/4999\n",
      "----------\n",
      "train Loss: 0.0623 Acc: 0.9713\n",
      "val Loss: 0.3698 Acc: 0.8889\n",
      "\n",
      "Epoch 249/4999\n",
      "----------\n",
      "train Loss: 0.0361 Acc: 0.9918\n",
      "val Loss: 0.3714 Acc: 0.8889\n",
      "\n",
      "Epoch 250/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0453 Acc: 0.9836\n",
      "val Loss: 0.3727 Acc: 0.8889\n",
      "\n",
      "Epoch 251/4999\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.9795\n",
      "val Loss: 0.3745 Acc: 0.8889\n",
      "\n",
      "Epoch 252/4999\n",
      "----------\n",
      "train Loss: 0.0622 Acc: 0.9795\n",
      "val Loss: 0.3767 Acc: 0.8889\n",
      "\n",
      "Epoch 253/4999\n",
      "----------\n",
      "train Loss: 0.0712 Acc: 0.9713\n",
      "val Loss: 0.3782 Acc: 0.8889\n",
      "\n",
      "Epoch 254/4999\n",
      "----------\n",
      "train Loss: 0.0405 Acc: 0.9877\n",
      "val Loss: 0.3787 Acc: 0.8889\n",
      "\n",
      "Epoch 255/4999\n",
      "----------\n",
      "train Loss: 0.0444 Acc: 0.9795\n",
      "val Loss: 0.3787 Acc: 0.8889\n",
      "\n",
      "Epoch 256/4999\n",
      "----------\n",
      "train Loss: 0.0398 Acc: 0.9836\n",
      "val Loss: 0.3798 Acc: 0.8889\n",
      "\n",
      "Epoch 257/4999\n",
      "----------\n",
      "train Loss: 0.0648 Acc: 0.9672\n",
      "val Loss: 0.3809 Acc: 0.8889\n",
      "\n",
      "Epoch 258/4999\n",
      "----------\n",
      "train Loss: 0.0489 Acc: 0.9713\n",
      "val Loss: 0.3817 Acc: 0.8889\n",
      "\n",
      "Epoch 259/4999\n",
      "----------\n",
      "train Loss: 0.0581 Acc: 0.9836\n",
      "val Loss: 0.3821 Acc: 0.8889\n",
      "\n",
      "Epoch 260/4999\n",
      "----------\n",
      "train Loss: 0.0653 Acc: 0.9795\n",
      "val Loss: 0.3822 Acc: 0.8889\n",
      "\n",
      "Epoch 261/4999\n",
      "----------\n",
      "train Loss: 0.0373 Acc: 0.9918\n",
      "val Loss: 0.3814 Acc: 0.8889\n",
      "\n",
      "Epoch 262/4999\n",
      "----------\n",
      "train Loss: 0.0265 Acc: 0.9877\n",
      "val Loss: 0.3806 Acc: 0.8889\n",
      "\n",
      "Epoch 263/4999\n",
      "----------\n",
      "train Loss: 0.0430 Acc: 0.9754\n",
      "val Loss: 0.3803 Acc: 0.8889\n",
      "\n",
      "Epoch 264/4999\n",
      "----------\n",
      "train Loss: 0.0765 Acc: 0.9713\n",
      "val Loss: 0.3812 Acc: 0.8889\n",
      "\n",
      "Epoch 265/4999\n",
      "----------\n",
      "train Loss: 0.0483 Acc: 0.9754\n",
      "val Loss: 0.3820 Acc: 0.8889\n",
      "\n",
      "Epoch 266/4999\n",
      "----------\n",
      "train Loss: 0.0653 Acc: 0.9672\n",
      "val Loss: 0.3815 Acc: 0.8954\n",
      "\n",
      "Epoch 267/4999\n",
      "----------\n",
      "train Loss: 0.0533 Acc: 0.9795\n",
      "val Loss: 0.3813 Acc: 0.8954\n",
      "\n",
      "Epoch 268/4999\n",
      "----------\n",
      "train Loss: 0.0507 Acc: 0.9836\n",
      "val Loss: 0.3819 Acc: 0.8954\n",
      "\n",
      "Epoch 269/4999\n",
      "----------\n",
      "train Loss: 0.0408 Acc: 0.9918\n",
      "val Loss: 0.3830 Acc: 0.8954\n",
      "\n",
      "Epoch 270/4999\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9877\n",
      "val Loss: 0.3842 Acc: 0.8954\n",
      "\n",
      "Epoch 271/4999\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.9836\n",
      "val Loss: 0.3866 Acc: 0.8889\n",
      "\n",
      "Epoch 272/4999\n",
      "----------\n",
      "train Loss: 0.0565 Acc: 0.9795\n",
      "val Loss: 0.3899 Acc: 0.8889\n",
      "\n",
      "Epoch 273/4999\n",
      "----------\n",
      "train Loss: 0.0577 Acc: 0.9754\n",
      "val Loss: 0.3927 Acc: 0.8889\n",
      "\n",
      "Epoch 274/4999\n",
      "----------\n",
      "train Loss: 0.0341 Acc: 0.9877\n",
      "val Loss: 0.3953 Acc: 0.8889\n",
      "\n",
      "Epoch 275/4999\n",
      "----------\n",
      "train Loss: 0.0370 Acc: 0.9918\n",
      "val Loss: 0.3964 Acc: 0.8889\n",
      "\n",
      "Epoch 276/4999\n",
      "----------\n",
      "train Loss: 0.0525 Acc: 0.9754\n",
      "val Loss: 0.3956 Acc: 0.8889\n",
      "\n",
      "Epoch 277/4999\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9877\n",
      "val Loss: 0.3949 Acc: 0.8889\n",
      "\n",
      "Epoch 278/4999\n",
      "----------\n",
      "train Loss: 0.0555 Acc: 0.9795\n",
      "val Loss: 0.3927 Acc: 0.8889\n",
      "\n",
      "Epoch 279/4999\n",
      "----------\n",
      "train Loss: 0.0582 Acc: 0.9795\n",
      "val Loss: 0.3893 Acc: 0.8889\n",
      "\n",
      "Epoch 280/4999\n",
      "----------\n",
      "train Loss: 0.0396 Acc: 0.9877\n",
      "val Loss: 0.3855 Acc: 0.8889\n",
      "\n",
      "Epoch 281/4999\n",
      "----------\n",
      "train Loss: 0.0477 Acc: 0.9836\n",
      "val Loss: 0.3835 Acc: 0.8954\n",
      "\n",
      "Epoch 282/4999\n",
      "----------\n",
      "train Loss: 0.0448 Acc: 0.9877\n",
      "val Loss: 0.3835 Acc: 0.8889\n",
      "\n",
      "Epoch 283/4999\n",
      "----------\n",
      "train Loss: 0.0280 Acc: 0.9918\n",
      "val Loss: 0.3845 Acc: 0.8889\n",
      "\n",
      "Epoch 284/4999\n",
      "----------\n",
      "train Loss: 0.0386 Acc: 0.9918\n",
      "val Loss: 0.3854 Acc: 0.8889\n",
      "\n",
      "Epoch 285/4999\n",
      "----------\n",
      "train Loss: 0.0387 Acc: 0.9877\n",
      "val Loss: 0.3863 Acc: 0.8889\n",
      "\n",
      "Epoch 286/4999\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.9795\n",
      "val Loss: 0.3870 Acc: 0.8889\n",
      "\n",
      "Epoch 287/4999\n",
      "----------\n",
      "train Loss: 0.0303 Acc: 0.9959\n",
      "val Loss: 0.3867 Acc: 0.8889\n",
      "\n",
      "Epoch 288/4999\n",
      "----------\n",
      "train Loss: 0.0618 Acc: 0.9754\n",
      "val Loss: 0.3859 Acc: 0.8889\n",
      "\n",
      "Epoch 289/4999\n",
      "----------\n",
      "train Loss: 0.0583 Acc: 0.9795\n",
      "val Loss: 0.3857 Acc: 0.8889\n",
      "\n",
      "Epoch 290/4999\n",
      "----------\n",
      "train Loss: 0.0355 Acc: 0.9877\n",
      "val Loss: 0.3852 Acc: 0.8889\n",
      "\n",
      "Epoch 291/4999\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 0.9795\n",
      "val Loss: 0.3846 Acc: 0.8889\n",
      "\n",
      "Epoch 292/4999\n",
      "----------\n",
      "train Loss: 0.0449 Acc: 0.9754\n",
      "val Loss: 0.3842 Acc: 0.8954\n",
      "\n",
      "Epoch 293/4999\n",
      "----------\n",
      "train Loss: 0.0370 Acc: 0.9877\n",
      "val Loss: 0.3839 Acc: 0.8954\n",
      "\n",
      "Epoch 294/4999\n",
      "----------\n",
      "train Loss: 0.0519 Acc: 0.9795\n",
      "val Loss: 0.3834 Acc: 0.8954\n",
      "\n",
      "Epoch 295/4999\n",
      "----------\n",
      "train Loss: 0.0238 Acc: 0.9918\n",
      "val Loss: 0.3833 Acc: 0.8954\n",
      "\n",
      "Epoch 296/4999\n",
      "----------\n",
      "train Loss: 0.0487 Acc: 0.9795\n",
      "val Loss: 0.3827 Acc: 0.8954\n",
      "\n",
      "Epoch 297/4999\n",
      "----------\n",
      "train Loss: 0.0444 Acc: 0.9836\n",
      "val Loss: 0.3813 Acc: 0.8954\n",
      "\n",
      "Epoch 298/4999\n",
      "----------\n",
      "train Loss: 0.0444 Acc: 0.9795\n",
      "val Loss: 0.3805 Acc: 0.8954\n",
      "\n",
      "Epoch 299/4999\n",
      "----------\n",
      "train Loss: 0.0446 Acc: 0.9836\n",
      "val Loss: 0.3804 Acc: 0.8954\n",
      "\n",
      "Epoch 300/4999\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0513 Acc: 0.9836\n",
      "val Loss: 0.3803 Acc: 0.8954\n",
      "\n",
      "Epoch 301/4999\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9918\n",
      "val Loss: 0.3800 Acc: 0.8954\n",
      "\n",
      "Epoch 302/4999\n",
      "----------\n",
      "train Loss: 0.0399 Acc: 0.9713\n",
      "val Loss: 0.3795 Acc: 0.8954\n",
      "\n",
      "Epoch 303/4999\n",
      "----------\n",
      "train Loss: 0.0419 Acc: 0.9836\n",
      "val Loss: 0.3796 Acc: 0.8954\n",
      "\n",
      "Epoch 304/4999\n",
      "----------\n",
      "train Loss: 0.0295 Acc: 0.9836\n",
      "val Loss: 0.3806 Acc: 0.8889\n",
      "\n",
      "Epoch 305/4999\n",
      "----------\n",
      "train Loss: 0.0294 Acc: 0.9918\n",
      "val Loss: 0.3827 Acc: 0.8889\n",
      "\n",
      "Epoch 306/4999\n",
      "----------\n",
      "train Loss: 0.0248 Acc: 0.9918\n",
      "val Loss: 0.3844 Acc: 0.8889\n",
      "\n",
      "Epoch 307/4999\n",
      "----------\n",
      "train Loss: 0.0720 Acc: 0.9713\n",
      "val Loss: 0.3837 Acc: 0.8889\n",
      "\n",
      "Epoch 308/4999\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9877\n",
      "val Loss: 0.3807 Acc: 0.8889\n",
      "\n",
      "Epoch 309/4999\n",
      "----------\n",
      "train Loss: 0.0497 Acc: 0.9836\n",
      "val Loss: 0.3798 Acc: 0.8889\n",
      "\n",
      "Epoch 310/4999\n",
      "----------\n",
      "train Loss: 0.0654 Acc: 0.9672\n",
      "val Loss: 0.3795 Acc: 0.8889\n",
      "\n",
      "Epoch 311/4999\n",
      "----------\n",
      "train Loss: 0.0406 Acc: 0.9918\n",
      "val Loss: 0.3797 Acc: 0.8889\n",
      "\n",
      "Epoch 312/4999\n",
      "----------\n",
      "train Loss: 0.0493 Acc: 0.9836\n",
      "val Loss: 0.3818 Acc: 0.8889\n",
      "\n",
      "Epoch 313/4999\n",
      "----------\n",
      "train Loss: 0.0370 Acc: 0.9918\n",
      "val Loss: 0.3834 Acc: 0.8889\n",
      "\n",
      "Epoch 314/4999\n",
      "----------\n",
      "train Loss: 0.0326 Acc: 0.9918\n",
      "val Loss: 0.3843 Acc: 0.8889\n",
      "\n",
      "Epoch 315/4999\n",
      "----------\n",
      "train Loss: 0.0483 Acc: 0.9877\n",
      "val Loss: 0.3843 Acc: 0.8889\n",
      "\n",
      "Epoch 316/4999\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9836\n",
      "val Loss: 0.3832 Acc: 0.8889\n",
      "\n",
      "Epoch 317/4999\n",
      "----------\n",
      "train Loss: 0.0634 Acc: 0.9754\n",
      "val Loss: 0.3814 Acc: 0.8889\n",
      "\n",
      "Epoch 318/4999\n",
      "----------\n",
      "train Loss: 0.0359 Acc: 0.9918\n",
      "val Loss: 0.3808 Acc: 0.8824\n",
      "\n",
      "Epoch 319/4999\n",
      "----------\n",
      "train Loss: 0.0313 Acc: 0.9959\n",
      "val Loss: 0.3813 Acc: 0.8824\n",
      "\n",
      "Epoch 320/4999\n",
      "----------\n",
      "train Loss: 0.0447 Acc: 0.9795\n",
      "val Loss: 0.3819 Acc: 0.8824\n",
      "\n",
      "Epoch 321/4999\n",
      "----------\n",
      "train Loss: 0.0628 Acc: 0.9713\n",
      "val Loss: 0.3820 Acc: 0.8824\n",
      "\n",
      "Epoch 322/4999\n",
      "----------\n",
      "train Loss: 0.0456 Acc: 0.9795\n",
      "val Loss: 0.3820 Acc: 0.8824\n",
      "\n",
      "Epoch 323/4999\n",
      "----------\n",
      "train Loss: 0.0448 Acc: 0.9795\n",
      "val Loss: 0.3824 Acc: 0.8824\n",
      "\n",
      "Epoch 324/4999\n",
      "----------\n",
      "train Loss: 0.0544 Acc: 0.9672\n",
      "val Loss: 0.3829 Acc: 0.8824\n",
      "\n",
      "Epoch 325/4999\n",
      "----------\n",
      "train Loss: 0.0713 Acc: 0.9713\n",
      "val Loss: 0.3841 Acc: 0.8889\n",
      "\n",
      "Epoch 326/4999\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9795\n",
      "val Loss: 0.3855 Acc: 0.8889\n",
      "\n",
      "Epoch 327/4999\n",
      "----------\n",
      "train Loss: 0.0228 Acc: 0.9959\n",
      "val Loss: 0.3864 Acc: 0.8889\n",
      "\n",
      "Epoch 328/4999\n",
      "----------\n",
      "train Loss: 0.0239 Acc: 0.9918\n",
      "val Loss: 0.3872 Acc: 0.8889\n",
      "\n",
      "Epoch 329/4999\n",
      "----------\n",
      "train Loss: 0.0426 Acc: 0.9836\n",
      "val Loss: 0.3872 Acc: 0.8889\n",
      "\n",
      "Epoch 330/4999\n",
      "----------\n",
      "train Loss: 0.0392 Acc: 0.9795\n",
      "val Loss: 0.3861 Acc: 0.8889\n",
      "\n",
      "Epoch 331/4999\n",
      "----------\n",
      "train Loss: 0.0393 Acc: 0.9836\n",
      "val Loss: 0.3849 Acc: 0.8889\n",
      "\n",
      "Epoch 332/4999\n",
      "----------\n",
      "train Loss: 0.0450 Acc: 0.9836\n",
      "val Loss: 0.3837 Acc: 0.8889\n",
      "\n",
      "Epoch 333/4999\n",
      "----------\n",
      "train Loss: 0.0594 Acc: 0.9836\n",
      "val Loss: 0.3822 Acc: 0.8889\n",
      "\n",
      "Epoch 334/4999\n",
      "----------\n",
      "train Loss: 0.0427 Acc: 0.9795\n",
      "val Loss: 0.3807 Acc: 0.8889\n",
      "\n",
      "Epoch 335/4999\n",
      "----------\n",
      "train Loss: 0.0423 Acc: 0.9918\n",
      "val Loss: 0.3799 Acc: 0.8889\n",
      "\n",
      "Epoch 336/4999\n",
      "----------\n",
      "train Loss: 0.0541 Acc: 0.9836\n",
      "val Loss: 0.3800 Acc: 0.8824\n",
      "\n",
      "Epoch 337/4999\n",
      "----------\n",
      "train Loss: 0.0425 Acc: 0.9836\n",
      "val Loss: 0.3813 Acc: 0.8824\n",
      "\n",
      "Epoch 338/4999\n",
      "----------\n",
      "train Loss: 0.0318 Acc: 0.9918\n",
      "val Loss: 0.3827 Acc: 0.8954\n",
      "\n",
      "Epoch 339/4999\n",
      "----------\n",
      "train Loss: 0.0310 Acc: 0.9877\n",
      "val Loss: 0.3840 Acc: 0.8889\n",
      "\n",
      "Epoch 340/4999\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _ConnectionBase.__del__ at 0x7f80396255f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kaizhang/.conda/envs/prune/lib/python3.7/multiprocessing/connection.py\", line 132, in __del__\n",
      "    self._close()\n",
      "  File \"/home/kaizhang/.conda/envs/prune/lib/python3.7/multiprocessing/connection.py\", line 361, in _close\n",
      "    _close(self._handle)\n",
      "OSError: [Errno 9] Bad file descriptor\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8bf8ce4eb91b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mscratch_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscratch_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mscratch_criterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscratch_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscratch_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscratch_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscratch_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inception\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"inception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-74369379ea54>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "# scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "\n",
    "# ============= For fair comparison, should use pretrained, and only update the last few layers ===========\n",
    "if model_name == \"alexnet\":\n",
    "    scratch_model = models.alexnet(pretrained=True)\n",
    "elif model_name == \"vgg\":\n",
    "    scratch_model = models.vgg19(pretrained=True)\n",
    "    \n",
    "    \n",
    "for param in scratch_model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for name, param in scratch_model.named_parameters():\n",
    "    print(\"\\t\",name, param.requires_grad)\n",
    "    \n",
    "print(scratch_model)\n",
    "\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_name == \"alexnet\":\n",
    "    torch.save(scratch_model.state_dict()['classifier.1.weight'], 'ant_bee_Alexnet_ScratchModel_acc8889_weight.pt')\n",
    "    torch.save(scratch_model.state_dict()['classifier.1.bias'], 'ant_bee_Alexnet_ScratchModel_acc8889_bias.pt')\n",
    "elif model_name == \"vgg\":\n",
    "    torch.save(scratch_model.state_dict()['classifier.weight'], 'ant_bee_VGG19_ScratchModel_acc_weight.pt')\n",
    "    torch.save(scratch_model.state_dict()['classifier.bias'], 'ant_bee_VGG19_ScratchModel_acc_bias.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scratch_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2be2a8995777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mohist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscratch_hist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot the training curves of validation accuracy vs. number \n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Thoughts and Where to Go Next\n",
    "-----------------------------------\n",
    "\n",
    "Try running some of the other models and see how good the accuracy gets.\n",
    "Also, notice that feature extracting takes less time because in the\n",
    "backward pass we do not have to calculate most of the gradients. There\n",
    "are many places to go from here. You could:\n",
    "\n",
    "-  Run this code with a harder dataset and see some more benefits of\n",
    "   transfer learning\n",
    "-  Using the methods described here, use transfer learning to update a\n",
    "   different model, perhaps in a new domain (i.e. NLP, audio, etc.)\n",
    "-  Once you are happy with a model, you can export it as an ONNX model,\n",
    "   or trace it using the hybrid frontend for more speed and optimization\n",
    "   opportunities.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
